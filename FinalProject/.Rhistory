View(order.summary)
customer.summary <- f_basic_summary(group_by(retail.data, CustomerID))
View(customer.summary)
View(order.summary)
40*3.91
qplot(order.summary$InvoiceDate, order.summary$volume)
qplot(order.summary$InvoiceDate, order.summary$total.contribution)
daily.summary <- f_basic_summary(group_by(retail.data, day.of.week))
View(daily.summary)
qplot(order.summary$volume, order.summary$total.contribution)
#### Analyses To Do: ####
# Check normality and transform
# By-order summary
# Region by day/week/month
# Customer segmentation & comparison of purchasing behavior between segments
# Customer lifetime value analysis
# Bootstrap interesting relationships for deeper investigation
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Load libraries ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(dplyr)
library(lubridate)
library(reshape2)
library(ggplot2)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Import and format dataset ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Online retail dataset from UCI ML library
# Source: https://archive.ics.uci.edu/ml/datasets/Online+Retail
retail.data <- read.csv("data/OnlineRetail.csv", stringsAsFactors = FALSE)
## Set formats
# Review original types
str(retail.data)
# Set factors
factor.cols <- c("InvoiceNo", "StockCode", "CustomerID", "Country")
retail.data[, factor.cols] <- lapply(retail.data[factor.cols], as.factor)
# Set dates
date.cols <- c("InvoiceDate")
retail.data[, date.cols] <- lapply(retail.data[date.cols], mdy_hm)
# Confirm types
str(retail.data)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Define Functions ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Returns processing function.
f_process_returns <- function(order.data) {
# Flog orders as returns
return.columns <- c("InvoiceNo", "StockCode", "CustomerID", "Quantity")
return.index <- grep("c", order.data$InvoiceNo, ignore.case = TRUE)
order.data$return <- FALSE
order.data$return[return.index] <- TRUE
# Generate synthetic key of customer-SKU combination to simplify window functions
order.data$syn.key <- paste(order.data$CustomerID, order.data$StockCode, sep = "")
####### Loop this:
## Nice test customer: zz <- order.data %>% filter(CustomerID == 12471)
returns.left <- length(which(order.data$return == TRUE))
order.data$adj.qty <- order.data$Quantity
order.data <- order.data %>% arrange(syn.key, InvoiceDate)
while (returns.left > 0 ) {
# Subtract quantity from prior customer order
order.data <- order.data %>% mutate(prior.qty = ifelse(syn.key == lag(syn.key), lag(Quantity), 0))
order.data$prior.qty <- replace(order.data$prior.qty, is.na(order.data$prior.qty), 0)
# When current is order and leading, matching synkey is a return, subtract from the current order
order.data <- order.data %>% mutate(adj.qty = ifelse(lead(syn.key) == syn.key & return == FALSE & lead(return) == TRUE, adj.qty + lead(adj.qty), adj.qty))
# When current synkey is a return and prior is an order, set adj.qty = 0 (flag for deletion)
order.data <- order.data %>% mutate(adj.qty = ifelse(lag(syn.key) == syn.key & return == TRUE & lag(return) == FALSE, 0, adj.qty))
# Remove RETURNS with no leading ORDER
order.data <- order.data %>% mutate(adj.qty = ifelse(return == TRUE & prior.qty == 0, 0, adj.qty))
# Remove rows where adj.qty = 0
order.data <- order.data %>% filter(adj.qty != 0)
# Set RETURN on all negative quantities to TRUE
order.data <- order.data %>% mutate(return = ifelse(adj.qty < 0, TRUE, FALSE))
# Are there any returns left?
returns.left <- length(which(order.data$return == TRUE))
print(returns.left)
}
order.data <- order.data %>% select(-prior.qty, -syn.key, -return)
return(order.data)
}
# Normality tests
f_norm_test <- function(data) {
qqnorm(data)
qqline(data)
}
# Summarization function for aggregate statistics
f_basic_summary <- function(grouped.data) {
current.summary <- summarise(grouped.data,
orders = n_distinct(InvoiceNo),
customers = n_distinct(CustomerID),
volume = sum(adj.qty),
log.volume = log(sum(adj.qty)),
total.contribution = sum(adj.qty * UnitPrice),
log.total.contribution = log(sum(adj.qty * UnitPrice)),
mean.contribution = mean(UnitPrice),
log.mean.contribution = log(mean(UnitPrice)))
return(current.summary)
}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Cleansing ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Remove orders from customers not registered with the site
retail.data <- retail.data %>% filter(!is.na(CustomerID))
# Remove abnormal SKUs
bad.SKU.index <- which(retail.data$StockCode %in% c("BANK CHARGES", "POST", "M", "PADS", "DOT", "CRUK", "D", "C2"))
retail.data <- retail.data[-bad.SKU.index,]
# Clean up returns
retail.data <- f_process_returns(retail.data)
# Add extended cost column
retail.data <- retail.data %>% mutate(ext.cost = UnitPrice * adj.qty)
retail.data <- retail.data %>% filter(ext.cost != 0)
# Extract interesting date characteristics
retail.data$day.of.week <- wday(retail.data$InvoiceDate, label = TRUE)
retail.data$month <- month(retail.data$InvoiceDate, label = TRUE)
retail.data$year <- year(retail.data$InvoiceDate)
retail.data$day.of.month <- mday(retail.data$InvoiceDate)
# Drop extinct levels
retail.data <- droplevels(retail.data)
order.summary <- f_basic_summary(group_by(retail.data, InvoiceNo, CustomerID, InvoiceDate))
SKU.summary <- f_basic_summary(group_by(retail.data, StockCode))
daily.summary <- f_basic_summary(group_by(retail.data, day.of.week))
day.of.month.summary <- f_basic_summary(group_by(retail.data, day.of.month))
monthly.summary <- f_basic_summary(group_by(retail.data, month))
monthly.SKU.summary <- f_basic_summary(group_by(retail.data, StockCode, month))  # Are some items summer items? Holiday items?
customer.summary <- f_basic_summary(group_by(retail.data, CustomerID))
customer.SKU.summary <- f_basic_summary(group_by(retail.data, CustomerID, StockCode))
region.summary <- f_basic_summary(group_by(retail.data, Country))
region.SKU.summary <- f_basic_summary(group_by(retail.data, Country, StockCode))  # Are local affinities apparent?
View(customer.summary)
View(order.summary)
hist(order.summary$volume)
hist(order.summary$log.volume)
exp(mean(order.summary$log.volume))
View(customer.SKU.summary)
View(SKU.summary)
SKU.summary$StockCode[1]
SKU.summary$StockCode[1] == 10002
sku.data <- retail.data %>% filter(StockCode == sku)
sku <- 22423
sku.data <- retail.data %>% filter(StockCode == sku)
View(sku.data)
qplot(sku.data$InvoiceDate, sku.data$Quantity)
qplot(sku.data$day.of.week, sku.data$Quantity)
sku.monthly <- f_basic_summary(group_by(sku.data, month))
View(SKU.summary)
View(monthly.summary)
View(sku.monthly)
qplot(sku.monthly$month, sku.monthly$orders)
qplot(sku.monthly$month, sku.monthly$volume)
View(monthly.summary)
View(retail.data)
retail.data$week <- week(retail.data$InvoiceDate)
sku <- 22423
sku.data <- retail.data %>% filter(StockCode == sku)
sku.weekly <- f_basic_summary(group_by(sku.data, week))
View(sku.weekly)
qplot(sku.weekly$week, sku.weekly$volume)
?qplot
qplot(sku.weekly$week, sku.weekly$volume, geom = "line")
qplot(sku.weekly$week, sku.weekly$volume, geom = c("line", "point"))
sku <- "85123A"
sku.data <- retail.data %>% filter(StockCode == sku)
sku.monthly <- f_basic_summary(group_by(sku.data, month))
sku.weekly <- f_basic_summary(group_by(sku.data, week))
qplot(sku.weekly$week, sku.weekly$volume)
qplot(sku.weekly$week, sku.weekly$volume, geom = c("line", "point"))
retail.data$week <- week(retail.data$InvoiceDate)
qplot(sku.monthly$month, sku.monthly$volume, geom = c("line", "point"))
qplot(sku.weekly$week, sku.weekly$volume, geom = c("line", "point"))
qplot(sku.monthly$month, sku.monthly$volume, geom = c("line", "point"))
View(sku.monthly)
View(sku.weekly)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Load libraries ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
library(dplyr)
library(lubridate)
library(reshape2)
library(ggplot2)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Import and format dataset ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Online retail dataset from UCI ML library
# Source: https://archive.ics.uci.edu/ml/datasets/Online+Retail
retail.data <- read.csv("data/OnlineRetail.csv", stringsAsFactors = FALSE)
## Set formats
# Review original types
str(retail.data)
# Set factors
factor.cols <- c("InvoiceNo", "StockCode", "CustomerID", "Country")
retail.data[, factor.cols] <- lapply(retail.data[factor.cols], as.factor)
# Set dates
date.cols <- c("InvoiceDate")
retail.data[, date.cols] <- lapply(retail.data[date.cols], mdy_hm)
# Confirm types
str(retail.data)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Define Functions ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Returns processing function.
f_process_returns <- function(order.data) {
# Flog orders as returns
return.columns <- c("InvoiceNo", "StockCode", "CustomerID", "Quantity")
return.index <- grep("c", order.data$InvoiceNo, ignore.case = TRUE)
order.data$return <- FALSE
order.data$return[return.index] <- TRUE
# Generate synthetic key of customer-SKU combination to simplify window functions
order.data$syn.key <- paste(order.data$CustomerID, order.data$StockCode, sep = "")
####### Loop this:
## Nice test customer: zz <- order.data %>% filter(CustomerID == 12471)
returns.left <- length(which(order.data$return == TRUE))
order.data$adj.qty <- order.data$Quantity
order.data <- order.data %>% arrange(syn.key, InvoiceDate)
while (returns.left > 0 ) {
# Subtract quantity from prior customer order
order.data <- order.data %>% mutate(prior.qty = ifelse(syn.key == lag(syn.key), lag(Quantity), 0))
order.data$prior.qty <- replace(order.data$prior.qty, is.na(order.data$prior.qty), 0)
# When current is order and leading, matching synkey is a return, subtract from the current order
order.data <- order.data %>% mutate(adj.qty = ifelse(lead(syn.key) == syn.key & return == FALSE & lead(return) == TRUE, adj.qty + lead(adj.qty), adj.qty))
# When current synkey is a return and prior is an order, set adj.qty = 0 (flag for deletion)
order.data <- order.data %>% mutate(adj.qty = ifelse(lag(syn.key) == syn.key & return == TRUE & lag(return) == FALSE, 0, adj.qty))
# Remove RETURNS with no leading ORDER
order.data <- order.data %>% mutate(adj.qty = ifelse(return == TRUE & prior.qty == 0, 0, adj.qty))
# Remove rows where adj.qty = 0
order.data <- order.data %>% filter(adj.qty != 0)
# Set RETURN on all negative quantities to TRUE
order.data <- order.data %>% mutate(return = ifelse(adj.qty < 0, TRUE, FALSE))
# Are there any returns left?
returns.left <- length(which(order.data$return == TRUE))
print(returns.left)
}
order.data <- order.data %>% select(-prior.qty, -syn.key, -return)
return(order.data)
}
# Normality tests
f_norm_test <- function(data) {
qqnorm(data)
qqline(data)
}
# Summarization function for aggregate statistics
f_basic_summary <- function(grouped.data) {
current.summary <- summarise(grouped.data,
orders = n_distinct(InvoiceNo),
customers = n_distinct(CustomerID),
volume = sum(adj.qty),
log.volume = log(sum(adj.qty)),
total.contribution = sum(adj.qty * UnitPrice),
log.total.contribution = log(sum(adj.qty * UnitPrice)),
mean.contribution = mean(UnitPrice),
log.mean.contribution = log(mean(UnitPrice)))
return(current.summary)
}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Cleansing ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# Remove orders from customers not registered with the site
retail.data <- retail.data %>% filter(!is.na(CustomerID))
# Remove abnormal SKUs
bad.SKU.index <- which(retail.data$StockCode %in% c("BANK CHARGES", "POST", "M", "PADS", "DOT", "CRUK", "D", "C2"))
retail.data <- retail.data[-bad.SKU.index,]
# Clean up returns
retail.data <- f_process_returns(retail.data)
# Add extended cost column
retail.data <- retail.data %>% mutate(ext.cost = UnitPrice * adj.qty)
retail.data <- retail.data %>% filter(ext.cost != 0)
# Extract interesting date characteristics
retail.data$day.of.week <- wday(retail.data$InvoiceDate, label = TRUE)
retail.data$month <- month(retail.data$InvoiceDate, label = TRUE)
retail.data$week <- week(retail.data$InvoiceDate)
retail.data$year <- year(retail.data$InvoiceDate)
retail.data$day.of.month <- mday(retail.data$InvoiceDate)
# Drop extinct levels
retail.data <- droplevels(retail.data)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Summary stats and plots
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
## Generate alternate view where SKUs are collapsed into a single ORDER row
order.summary <- f_basic_summary(group_by(retail.data, InvoiceNo, CustomerID, InvoiceDate))
# qplot(order.summary$InvoiceDate, order.summary$total.contribution)
# qplot(order.summary$volume, order.summary$total.contribution)
########################################## Continue exploring this thread- can we segment customers here? E.g. Add order frequency, size...
## SKU popularity
SKU.summary <- f_basic_summary(group_by(retail.data, StockCode))
# pairs(SKU.summary)
# Insights:
# 1) There appears to be grouping of SKUs by item type, as seen by SKU-mean.contribution relationship
# 2) # of orders and # of customers by SKU is strongly co-linear, as expected
# 3) # of orders against volume by SKU shows a range.
# 4) Cheaper items make the most revenue and volume in total as seen in mean.contribution - total.contribution chart
## Trends by day of week
daily.summary <- f_basic_summary(group_by(retail.data, day.of.week))
# pairs(daily.summary)
# Insights:
# 1) The shop is closed on Saturday (1 = Sunday, 6 = Friday)
# 2) Order activity is lowest on Sunday, ramping up to a peak on Thursday and dropping off on Friday
# 3) # of orders, customers, volume, and total contribution are all co-linear on the same pattern
# 4) Sunday is the most frugal day. During the week, the mean cost of goods is inversely proportional to sales activity.
#    As order intake increases, mean prices decrease. We see maxima on Monday and Friday. Perhaps reflecting the dynamics
#    of sales to resellers during midweek and consumers on Monday/Friday?
## Trends by day of month
day.of.month.summary <- f_basic_summary(group_by(retail.data, day.of.month))
# pairs(day.of.month.summary)
# Insights:
# 1) Order intake peaks at beginning of month and drops off over the course of the month
## Trends by month
monthly.summary <- f_basic_summary(group_by(retail.data, month))
monthly.SKU.summary <- f_basic_summary(group_by(retail.data, StockCode, month))  # Are some items summer items? Holiday items?
# pairs(monthly.summary)
# Insights:
# 1) Order volume is lowest in Jan/Feb, then steadily ramps up to a peak in November, slight drop in December
# 2) Mean price peaks in the summer months, and reaches it's lowest point in the highest volume month of November.
## Trends by customer
customer.summary <- f_basic_summary(group_by(retail.data, CustomerID))
customer.SKU.summary <- f_basic_summary(group_by(retail.data, CustomerID, StockCode))
# pairs(customer.summary)
# qplot(mean.contribution, total.contribution, data = customer.summary)
# Insights:
# 1) Broad spectrum of customer types, generally spreading out in 2 directions; low volume/high cost & high volume/low cost
## Regional trends
region.summary <- f_basic_summary(group_by(retail.data, Country))
region.SKU.summary <- f_basic_summary(group_by(retail.data, Country, StockCode))  # Are local affinities apparent?
# pairs(region.summary)
# Insights:
# 1) The UK is, by far the largest customer
# 2) Singapore stands out as an outlier for high mean contribution. Interestingly, there is only a single customer that has
#    placed 10 orders for >5,000 items with a mean contribution of >$100 per item.
sku <- 22423
sku.data <- retail.data %>% filter(StockCode == sku)
sku.monthly <- f_basic_summary(group_by(sku.data, month))
sku.weekly <- f_basic_summary(group_by(sku.data, week))
qplot(sku.monthly$month, sku.monthly$volume, geom = c("line", "point"))
qplot(sku.weekly$week, sku.weekly$volume, geom = c("line", "point"))
View(sku.monthly)
View(sku.data)
View(SKU.summary)
sku <- "85099B"
sku.data <- retail.data %>% filter(StockCode == sku)
sku.monthly <- f_basic_summary(group_by(sku.data, month))
sku.weekly <- f_basic_summary(group_by(sku.data, week))
qplot(sku.monthly$month, sku.monthly$volume, geom = c("line", "point"))
qplot(sku.weekly$week, sku.weekly$volume, geom = c("line", "point"))
sku <- "84879"
sku.data <- retail.data %>% filter(StockCode == sku)
sku.monthly <- f_basic_summary(group_by(sku.data, month))
sku.weekly <- f_basic_summary(group_by(sku.data, week))
qplot(sku.monthly$month, sku.monthly$volume, geom = c("line", "point"))
qplot(sku.weekly$week, sku.weekly$volume, geom = c("line", "point"))
View(sku.monthly)
View(sku.weekly)
View(SKU.summary)
str(retail.data)
View(customer.summary)
hist(customer.summary$orders)
hist(customer.summary$orders, breaks = 30)
hist(log(customer.summary$orders), breaks = 30)
View(retail.data)
today <- mdy("12-10-2011")
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
mutate(frequency = n(),
recency = as.numeric(today - InvoiceDate)) %>%
filter(InvoiceDate == max(InvoiceDate)) %>%
ungroup()
View(customer.metrics)
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
mutate(frequency = n(),
recency = (today - InvoiceDate)) %>%
filter(InvoiceDate == max(InvoiceDate)) %>%
ungroup()
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n())
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = max(InvoiceDate))
today
today - customer.metrics[1]
class(customer.metrics[1])
class(today)
today <- mdy_hm("12-10-2011 12:00")
class(today)
class(customer.metrics[1])
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = mdy_hm(max(InvoiceDate)))
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = max(InvoiceDate))
today <- mdy_hm("12-10-2011 12:00")
today - customer.metrics[1]
customer.metrics$recency[1]
class(customer.metrics$recency[1])
class(today)
today - customer.metrics$recency[1]
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = today - max(InvoiceDate))
hist(customer.metrics$frequency)
hist(customer.metrics$recency)
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)))
hist(customer.metrics$frequency)
hist(customer.metrics$recency)
hist(log(customer.metrics$frequency))
qqplot(customer.metrics$frequency)
qqPlot(customer.metrics$frequency)
qqnorm(customer.metrics$frequency)
qqnorm(log(customer.metrics$frequency))
qqnorm(log(customer.metrics$recency))
qqnorm(customer.metrics$recency)
qqline(customer.metrics$recency)
qqnorm(log(customer.metrics$recency))
qqline(log(customer.metrics$recency))
hist(log(customer.metrics$frequency))
hist(log(customer.metrics$recency))
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)),
log.frequency = log(frequency),
log.recency = log(recency))
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)),
log.frequency = log(frequency),
log.recency = log(recency),
last.order = max(InvoiceDate))
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)),
log.frequency = log(frequency),
log.recency = log(recency),
last.order = max(InvoiceNo))
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)),
log.frequency = log(frequency),
log.recency = log(recency),
last.order = max(as.numeric(InvoiceNo)))
zz <- retail.data %>% filter(CustomerID == 12347)
View(zz)
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)),
log.frequency = log(frequency),
log.recency = log(recency),
last.order = max(as.character(InvoiceNo)))
hist(customer.metrics$log.recency)
hist(customer.metrics$log.frequency)
quantile(customer.metrics$log.recency)
?quantile
round(quantile(customer.metrics$log.recency))
max(customer.metrics$log.recency)
round(quantile(customer.metrics$log.recency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9)))
round(quantile(customer.metrics$recency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9)))
quantile(customer.metrics$recency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9))
quantile(customer.metrics$log.recency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9))
quantile(customer.metrics$log.frequency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9))
recency.breaks <- quantile(customer.metrics$log.recency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9))
frequency.breaks <- quantile(customer.metrics$log.frequency, probs = c(0.15, 0.3, 0.45, 0.6, 0.75, 0.9))
?ntile
zz <- ntile(customer.metrics$log.recency, 6)
customer.metrics$recency.bin <- ntile(customer.metrics$log.recency)
customer.metrics$recency.bin <- ntile(customer.metrics$log.recency, 6)
customer.metrics$log.frequency <- ntile(customer.metrics$log.frequency, 6)
customer.metrics <- retail.data %>%
group_by(CustomerID) %>%
summarise(frequency = n(),
recency = as.numeric(today - max(InvoiceDate)),
log.frequency = log(frequency),
log.recency = log(recency),
last.order = max(as.character(InvoiceNo)))
hist(customer.metrics$log.recency)
hist(customer.metrics$log.frequency)
# Define breaks for frequency and recency (~6 each)
customer.metrics$recency.bin <- ntile(customer.metrics$log.recency, 6)
customer.metrics$frequency.bin <- ntile(customer.metrics$log.frequency, 6)
lifecycle.grid <- customer.metrics %>%
group_by(recency.bin, frequency.bin) %>%
summarise(quantity = n())
View(lifecycle.grid)
lifecycle.grid <- customer.metrics %>%
group_by(recency.bin, frequency.bin) %>%
summarise(quantity = n()) %>%
ungroup()
?dcast
lifecycle.grid <- dcast(lifecycle.grid, frequency.bin ~ recency.bin,
value.var = 'quantity', fun.aggregate = sum)
lifecycle.grid <- customer.metrics %>%
group_by(recency.bin, frequency.bin) %>%
summarise(quantity = n()) %>%
mutate(CustomerID = CustomerID) %>%
ungroup()
lifecycle.grid <- customer.metrics %>%
group_by(recency.bin, frequency.bin) %>%
summarise(quantity = n()) %>%
mutate(CustomerID = 'CustomerID') %>%
ungroup()
ggplot(lifecycle.grid, aes(x = CustomerID, y = quantity, fill = quantity)) +
geom_bar(stat = 'identity') +
facet_grid(frequency.bin ~ recency.bin)
hist(customer.metrics$recency.bin)
