---
title: 'Assignment 8: Bayesian Models'
author: "Danny Godbout"
date: "August 15, 2016"
output: html_document
---


```{r global_options, include = FALSE}
# Set global knitr options

knitr::opts_chunk$set(comment = "", echo = FALSE, warning = FALSE, message = FALSE)


```



##  {.tabset}

### Prior Distribution

From prior knowledge of national texting occurences (P = 0.5 @ X = 0.1, P = 0.75 @ X = 0.3), we calculate the beta coefficients for the prior distribution:

``` {r}
library(LearnBayes)

## Compute the Beta prior, and report the coefficents
beta.prior <- beta.select(list(p=0.5, x=0.1), list(p=0.75, x=.3))

## View the coefficients
beta.prior
```


### Update Beliefs

Three additional observations are made at a local intersection with the following impacts on posterior distributions:

* First Observation: 2 texting out of 20
``` {r}

# a. 2 texting out of 20 drivers
beta.prior + c(2, 18)
triplot(beta.prior, c(2, 18))

```

* Second Observation: 4 texting out of 20
``` {r}

# b. 4 texting out of 20 drivers
beta.prior + c(2 + 4, 18 + 16)
triplot(beta.prior, c(2 + 4, 18 + 16))

```

* Third Observation: 1 texting out of 20
``` {r}

# c. 1 texting out of 20 drivers
beta.prior + c(2 + 4 + 1, 18 + 16 + 19)
triplot(beta.prior, c(2 + 4 + 1, 18 + 16 + 19))

```


### Posterior Distribution

The final posterior distribution coefficients are calculated to be:

``` {r}
## Posterior distribution:
beta.post <- beta.prior + c(2 + 4 + 1, 18 + 16 + 19)

## Sample from distribution:
post.sample <- rbeta(10000, beta.post[1], beta.post[2])
quants = quantile(post.sample, c(0.05, 0.95))

```

Sampling from this distribution to generate a histogram of the highest density intervals generates the following plot with 90% HDI limits of `r quants`

``` {r}


## Plot HDI and QQ plot:
par(mfrow = c(1,2))
breaks = seq(min(post.sample), max(post.sample), length.out = 41)
hist(post.sample, breaks = breaks, 
     main = 'Distribution of samples \n with 90% HDI',
     xlab = 'Sample value',
     ylab = 'Density')
abline(v = quants[1], lty = 3, col = 'red', lwd = 3)
abline(v = quants[2], lty = 3, col = 'red', lwd = 3)
qqnorm(post.sample)
par(mfrow = c(1,1))
```

### Future Observations

``` {r}
f_predicted_probs <- function(beta, n, s) {
  pred.probs <- pbetap(beta, n, s)
  
  return(pred.probs)
}

f_prob_dist <- function(n = 100, beta, title) {
  # Function plots the distribution of events over n observations.
  s <- 0:n
  pred.probs <- f_predicted_probs(beta, n, s)
  discrete.distribution <- discint(cbind(s, pred.probs), 0.90)
  
  plot(s, pred.probs, type="h", 
       main = title,
       xlab = 'Texters')
  abline(v = max(discrete.distribution$set), lty = 3, col = 'red', lwd = 3)
  abline(v = min(discrete.distribution$set), lty = 3, col = 'red', lwd = 3)
}
```

Over the next 100 drivers, we can expect to see a result falling inside the following distribution; roughly between 6 and 20 texters, most likely `r which.max(f_predicted_probs(beta.post, n = 100, s = 0:100))`.

```{r}

# > Of the next hundred drivers what are the number of texting drivers
# in the 90% HDI?

## Plot the posterior distribution over 100 observations
f_prob_dist(n = 100, beta = beta.post, title = "Posterior distribution of texters")

```

### Quality of local drivers

Comparing our posterior distribution to national estimates we observe that we are less likely to see no texters in the local intersection, yet are also far less likely to see large numbers (>20) of texters as well. Our local intersection's HDI skew toward the lower end of the national observations.

```{r}

# > Are the drivers in this area better or worse that the national figures
# indicate?

f_prob_dist(beta = beta.prior, title = "National distribution of texters")
f_prob_dist(beta = beta.post, title = "Local distribution of texters")

```


### Source Code

``` {r, echo = TRUE, eval = FALSE}

library(LearnBayes)


#~~~~~~~~~~~~~~~~~~~~~~~~
#### National Priors ####
#~~~~~~~~~~~~~~~~~~~~~~~~

# Nationally the chance that a driver is texting is:
#   > P = 0.5, at x = 0.1
#   > P = 0.75 at x = 0.3
  
## Compute the Beta prior, and report the coefficents
beta.prior <- beta.select(list(p=0.5, x=0.1), list(p=0.75, x=.3))

## View the coefficients
beta.prior



#~~~~~~~~~~~~~~~~~~~~~~~~
#### Update beliefs  ####
#~~~~~~~~~~~~~~~~~~~~~~~~

## Plot the prior, likelihood and posterior three times as you update
## your belief based on collecting more data

par(mfrow = c(3,1))

# a. 2 texting out of 20 drivers
beta.prior + c(2, 18)
triplot(beta.prior, c(2, 18))

# b. 4 texting out of 20 drivers
beta.prior + c(2 + 4, 18 + 16)
triplot(beta.prior, c(2 + 4, 18 + 16))

# c. 1 texting out of 20 drivers
beta.prior + c(2 + 4 + 1, 18 + 16 + 19)
triplot(beta.prior, c(2 + 4 + 1, 18 + 16 + 19))

par(mfrow = c(1,1))



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#### Simulate final posterior  ####
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


# â€“ Simulate the final posterior distribution and do the following:
#   > Plot the posterior with the 90% HDI shown

## Posterior distribution:
beta.post <- beta.prior + c(2 + 4 + 1, 18 + 16 + 19)
## Sample from distribution:
post.sample <- rbeta(10000, beta.post[1], beta.post[2])

## Plot HDI and QQ plot:
par(mfrow = c(1,2))
quants = quantile(post.sample, c(0.05, 0.95))
breaks = seq(min(post.sample), max(post.sample), length.out = 41)
hist(post.sample, breaks = breaks, 
     main = 'Distribution of samples \n with 90% HDI',
     xlab = 'Sample value',
     ylab = 'Density')
abline(v = quants[1], lty = 3, col = 'red', lwd = 3)
abline(v = quants[2], lty = 3, col = 'red', lwd = 3)
qqnorm(post.sample)
par(mfrow = c(1,1))



# > Report the upper and lower limits of the 90% HDI
quants



# > Of the next hundred drivers what are the number of texting drivers
# in the 90% HDI?

f_predicted_probs <- function(beta, n, s) {
  pred.probs <- pbetap(beta, n, s)
  
  return(pred.probs)
}

f_prob_dist <- function(n = 100, beta, title) {
  # Function plots the distribution of events over n observations.
  s <- 0:n
  pred.probs <- f_predicted_probs(beta, n, s)
  discrete.distribution <- discint(cbind(s, pred.probs), 0.90)
  
  plot(s, pred.probs, type="h", 
       main = title,
       xlab = 'Texters')
  abline(v = max(discrete.distribution$set), lty = 3, col = 'red', lwd = 3)
  abline(v = min(discrete.distribution$set), lty = 3, col = 'red', lwd = 3)
}



## Plot the posterior distribution over 100 observations
f_prob_dist(n = 100, beta = beta.post, title = "Posterior distribution of texters")



# > Are the drivers in this area better or worse that the national figures
# indicate?
par(mfrow = c(2,1))
f_prob_dist(beta = beta.prior, title = "Prior distribution of texters")
f_prob_dist(beta = beta.post, title = "Posterior distribution of texters")
par(mfrow = c(1,1))


```